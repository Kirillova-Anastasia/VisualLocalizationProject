{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "003ff5d9-6806-4eeb-b1bc-32d95cab2f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a2027c6-58b9-48b9-89d1-50605b9f9430",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "mat = scipy.io.loadmat('pitts30k_test.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5a0ea951-fc1e-4e89-a230-b782e7bb9a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torch.utils.data as data\n",
    "\n",
    "from os.path import join, exists\n",
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "from random import randint, random\n",
    "from collections import namedtuple\n",
    "from PIL import Image\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import h5py\n",
    "\n",
    "root_dir = 'D:/datasets/'\n",
    "if not exists(root_dir):\n",
    "    raise FileNotFoundError('root_dir is hardcoded, please adjust to point to Pittsburth dataset')\n",
    "\n",
    "struct_dir = join(root_dir, 'datasets/')\n",
    "queries_dir = join(root_dir, 'queries_real')\n",
    "\n",
    "def input_transform():\n",
    "    return transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                               std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "\n",
    "def get_whole_training_set(onlyDB=False):\n",
    "    structFile = join(struct_dir, 'pitts30k_train.mat')\n",
    "    return WholeDatasetFromStruct(structFile,\n",
    "                             input_transform=input_transform(),\n",
    "                             onlyDB=onlyDB)\n",
    "\n",
    "def get_whole_val_set():\n",
    "    structFile = join(struct_dir, 'pitts30k_val.mat')\n",
    "    return WholeDatasetFromStruct(structFile,\n",
    "                             input_transform=input_transform())\n",
    "\n",
    "def get_250k_val_set():\n",
    "    structFile = join(struct_dir, 'pitts250k_val.mat')\n",
    "    return WholeDatasetFromStruct(structFile,\n",
    "                             input_transform=input_transform())\n",
    "def get_whole_test_set():\n",
    "    structFile = join(struct_dir, 'pitts30k_test.mat')\n",
    "    return WholeDatasetFromStruct(structFile,\n",
    "                             input_transform=input_transform())\n",
    "\n",
    "def get_250k_test_set():\n",
    "    structFile = join(struct_dir, 'pitts250k_test.mat')\n",
    "    return WholeDatasetFromStruct(structFile,\n",
    "                             input_transform=input_transform())\n",
    "\n",
    "def get_training_query_set(margin=0.1):\n",
    "    structFile = join(struct_dir, 'pitts30k_train.mat')\n",
    "    return QueryDatasetFromStruct(structFile,\n",
    "                             input_transform=input_transform(), margin=margin)\n",
    "\n",
    "def get_val_query_set():\n",
    "    structFile = join(struct_dir, 'pitts30k_val.mat')\n",
    "    return QueryDatasetFromStruct(structFile,\n",
    "                             input_transform=input_transform())\n",
    "\n",
    "def get_250k_val_query_set():\n",
    "    structFile = join(struct_dir, 'pitts250k_val.mat')\n",
    "    return QueryDatasetFromStruct(structFile,\n",
    "                             input_transform=input_transform())\n",
    "\n",
    "dbStruct = namedtuple('dbStruct', ['whichSet', 'dataset', \n",
    "    'dbImage', 'utmDb', 'qImage', 'utmQ', 'numDb', 'numQ',\n",
    "    'posDistThr', 'posDistSqThr', 'nonTrivPosDistSqThr'])\n",
    "\n",
    "def parse_dbStruct(path):\n",
    "    mat = loadmat(path)\n",
    "    matStruct = mat['dbStruct'].item()\n",
    "\n",
    "    if '250k' in path.split('/')[-1]:\n",
    "        dataset = 'pitts250k'\n",
    "    else:\n",
    "        dataset = 'pitts30k'\n",
    "\n",
    "    whichSet = matStruct[0].item()\n",
    "\n",
    "    dbImage = [f[0].item() for f in matStruct[1]]\n",
    "    utmDb = matStruct[2].T\n",
    "\n",
    "    qImage = [f[0].item() for f in matStruct[3]]\n",
    "    utmQ = matStruct[4].T\n",
    "\n",
    "    numDb = matStruct[5].item()\n",
    "    numQ = matStruct[6].item()\n",
    "\n",
    "    posDistThr = matStruct[7].item()\n",
    "    posDistSqThr = matStruct[8].item()\n",
    "    nonTrivPosDistSqThr = matStruct[9].item()\n",
    "\n",
    "    return dbStruct(whichSet, dataset, dbImage, utmDb, qImage, \n",
    "            utmQ, numDb, numQ, posDistThr, \n",
    "            posDistSqThr, nonTrivPosDistSqThr)\n",
    "\n",
    "class WholeDatasetFromStruct(data.Dataset):\n",
    "    def __init__(self, structFile, input_transform=None, onlyDB=False):\n",
    "        super().__init__()\n",
    "\n",
    "        self.input_transform = input_transform\n",
    "\n",
    "        self.dbStruct = parse_dbStruct(structFile)\n",
    "        self.images = [join(root_dir, dbIm) for dbIm in self.dbStruct.dbImage]\n",
    "        if not onlyDB:\n",
    "            self.images += [join(queries_dir, qIm) for qIm in self.dbStruct.qImage]\n",
    "\n",
    "        self.whichSet = self.dbStruct.whichSet\n",
    "        self.dataset = self.dbStruct.dataset\n",
    "\n",
    "        self.positives = None\n",
    "        self.distances = None\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img = Image.open(self.images[index])\n",
    "\n",
    "        if self.input_transform:\n",
    "            img = self.input_transform(img)\n",
    "\n",
    "        return img, index\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def getPositives(self):\n",
    "        # positives for evaluation are those within trivial threshold range\n",
    "        #fit NN to find them, search by radius\n",
    "        if  self.positives is None:\n",
    "            knn = NearestNeighbors(n_jobs=-1)\n",
    "            knn.fit(self.dbStruct.utmDb)\n",
    "\n",
    "            self.distances, self.positives = knn.radius_neighbors(self.dbStruct.utmQ,\n",
    "                    radius=self.dbStruct.posDistThr)\n",
    "\n",
    "        return self.positives\n",
    "        \n",
    "def collate_fn(batch):\n",
    "    \"\"\"Creates mini-batch tensors from the list of tuples (query, positive, negatives).\n",
    "    \n",
    "    Args:\n",
    "        data: list of tuple (query, positive, negatives). \n",
    "            - query: torch tensor of shape (3, h, w).\n",
    "            - positive: torch tensor of shape (3, h, w).\n",
    "            - negative: torch tensor of shape (n, 3, h, w).\n",
    "    Returns:\n",
    "        query: torch tensor of shape (batch_size, 3, h, w).\n",
    "        positive: torch tensor of shape (batch_size, 3, h, w).\n",
    "        negatives: torch tensor of shape (batch_size, n, 3, h, w).\n",
    "    \"\"\"\n",
    "\n",
    "    batch = list(filter (lambda x:x is not None, batch))\n",
    "    if len(batch) == 0: return None, None, None, None, None\n",
    "\n",
    "    query, positive, negatives, indices = zip(*batch)\n",
    "\n",
    "    query = data.dataloader.default_collate(query)\n",
    "    positive = data.dataloader.default_collate(positive)\n",
    "    negCounts = data.dataloader.default_collate([x.shape[0] for x in negatives])\n",
    "    negatives = torch.cat(negatives, 0)\n",
    "    import itertools\n",
    "    indices = list(itertools.chain(*indices))\n",
    "\n",
    "    return query, positive, negatives, negCounts, indices\n",
    "\n",
    "class QueryDatasetFromStruct(data.Dataset):\n",
    "    def __init__(self, structFile, nNegSample=1000, nNeg=10, margin=0.1, input_transform=None):\n",
    "        super().__init__()\n",
    "\n",
    "        self.input_transform = input_transform\n",
    "        self.margin = margin\n",
    "\n",
    "        self.dbStruct = parse_dbStruct(structFile)\n",
    "        self.whichSet = self.dbStruct.whichSet\n",
    "        self.dataset = self.dbStruct.dataset\n",
    "        self.nNegSample = nNegSample # number of negatives to randomly sample\n",
    "        self.nNeg = nNeg # number of negatives used for training\n",
    "\n",
    "        # potential positives are those within nontrivial threshold range\n",
    "        #fit NN to find them, search by radius\n",
    "        knn = NearestNeighbors(n_jobs=-1)\n",
    "        knn.fit(self.dbStruct.utmDb)\n",
    "\n",
    "        # TODO use sqeuclidean as metric?\n",
    "        self.nontrivial_positives = list(knn.radius_neighbors(self.dbStruct.utmQ,\n",
    "                radius=self.dbStruct.nonTrivPosDistSqThr**0.5, \n",
    "                return_distance=False))\n",
    "        # radius returns unsorted, sort once now so we dont have to later\n",
    "        for i,posi in enumerate(self.nontrivial_positives):\n",
    "            self.nontrivial_positives[i] = np.sort(posi)\n",
    "        # its possible some queries don't have any non trivial potential positives\n",
    "        # lets filter those out\n",
    "        self.queries = np.where(np.array([len(x) for x in self.nontrivial_positives])>0)[0]\n",
    "\n",
    "        # potential negatives are those outside of posDistThr range\n",
    "        potential_positives = knn.radius_neighbors(self.dbStruct.utmQ,\n",
    "                radius=self.dbStruct.posDistThr, \n",
    "                return_distance=False)\n",
    "\n",
    "        self.potential_negatives = []\n",
    "        for pos in potential_positives:\n",
    "            self.potential_negatives.append(np.setdiff1d(np.arange(self.dbStruct.numDb),\n",
    "                pos, assume_unique=True))\n",
    "\n",
    "        self.cache = None # filepath of HDF5 containing feature vectors for images\n",
    "\n",
    "        self.negCache = [np.empty((0,)) for _ in range(self.dbStruct.numQ)]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        index = self.queries[index] # re-map index to match dataset\n",
    "        with h5py.File(self.cache, mode='r') as h5: \n",
    "            h5feat = h5.get(\"features\")\n",
    "\n",
    "            qOffset = self.dbStruct.numDb \n",
    "            qFeat = h5feat[index+qOffset]\n",
    "\n",
    "            posFeat = h5feat[self.nontrivial_positives[index].tolist()]\n",
    "            knn = NearestNeighbors(n_jobs=-1) # TODO replace with faiss?\n",
    "            knn.fit(posFeat)\n",
    "            dPos, posNN = knn.kneighbors(qFeat.reshape(1,-1), 1)\n",
    "            dPos = dPos.item()\n",
    "            posIndex = self.nontrivial_positives[index][posNN[0]].item()\n",
    "\n",
    "            negSample = np.random.choice(self.potential_negatives[index], self.nNegSample)\n",
    "            negSample = np.unique(np.concatenate([self.negCache[index], negSample]))\n",
    "\n",
    "            negFeat = h5feat[negSample.tolist()]\n",
    "            knn.fit(negFeat)\n",
    "\n",
    "            dNeg, negNN = knn.kneighbors(qFeat.reshape(1,-1), \n",
    "                    self.nNeg*10) # to quote netvlad paper code: 10x is hacky but fine\n",
    "            dNeg = dNeg.reshape(-1)\n",
    "            negNN = negNN.reshape(-1)\n",
    "\n",
    "            # try to find negatives that are within margin, if there aren't any return none\n",
    "            violatingNeg = dNeg < dPos + self.margin**0.5\n",
    "     \n",
    "            if np.sum(violatingNeg) < 1:\n",
    "                #if none are violating then skip this query\n",
    "                return None\n",
    "\n",
    "            negNN = negNN[violatingNeg][:self.nNeg]\n",
    "            negIndices = negSample[negNN].astype(np.int32)\n",
    "            self.negCache[index] = negIndices\n",
    "\n",
    "        query = Image.open(join(queries_dir, self.dbStruct.qImage[index]))\n",
    "        positive = Image.open(join(root_dir, self.dbStruct.dbImage[posIndex]))\n",
    "\n",
    "        if self.input_transform:\n",
    "            query = self.input_transform(query)\n",
    "            positive = self.input_transform(positive)\n",
    "\n",
    "        negatives = []\n",
    "        for negIndex in negIndices:\n",
    "            negative = Image.open(join(root_dir, self.dbStruct.dbImage[negIndex]))\n",
    "            if self.input_transform:\n",
    "                negative = self.input_transform(negative)\n",
    "            negatives.append(negative)\n",
    "\n",
    "        negatives = torch.stack(negatives, 0)\n",
    "\n",
    "        return query, positive, negatives, [index, posIndex]+negIndices.tolist()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35064160-5dd2-44c1-bcac-7547a88aacdb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
